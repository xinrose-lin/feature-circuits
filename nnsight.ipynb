{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/asyncio/base_events.py\", line 604, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_136927/4100684961.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/common/home/users/x/xinrose.lin.2020/.conda/envs/fcs/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "input_size = 5\n",
    "hidden_dims = 10\n",
    "output_size = 2\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    OrderedDict(\n",
    "        [\n",
    "            (\"layer1\", torch.nn.Linear(input_size, hidden_dims)),\n",
    "            (\"layer2\", torch.nn.Linear(hidden_dims, output_size)),\n",
    "        ]\n",
    "    )\n",
    ").requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=5, out_features=10, bias=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (layer1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (layer2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "<class 'nnsight.models.NNsightModel.NNsight'>\n"
     ]
    }
   ],
   "source": [
    "import nnsight\n",
    "from nnsight import NNsight\n",
    "\n",
    "tiny_model = NNsight(net)\n",
    "print(tiny_model)\n",
    "print(type(tiny_model)) ## a wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0433, 0.3610, 0.4363, 0.3334, 0.1572]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "&lt;Tracer at 0x7f14328e5310&gt;"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### python contexts: define scope \"with\"\n",
    "### with open (my file) as file \n",
    "### being within context: file is open; \n",
    "### being outside context: file is closed \n",
    "\n",
    "### context for tracing: \n",
    "input = torch.rand((1, input_size))\n",
    "print(input)\n",
    "tiny_model.trace(input) ## creates tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on NNsight in module nnsight.models.NNsightModel object:\n",
      "\n",
      "class NNsight(builtins.object)\n",
      " |  NNsight(*args, **kwargs) -> 'Self | Envoy'\n",
      " |  \n",
      " |  Main class to be implemented as a wrapper for PyTorch models wishing to gain this package's functionality. Can be used \"as is\" for basic models.\n",
      " |  \n",
      " |  Class Attributes:\n",
      " |  \n",
      " |      proxy_class (Type[InterventionProxy]): InterventionProxy like type to use as a Proxy for this Model's inputs and outputs. Can have Model specific functionality added to a new sub-class.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      _model_key (str): String representing what kind of model this is. Usually hugging face repo id of model to load, path to checkpoint, or class name of custom model.\n",
      " |      _args (List[Any]): Positional arguments used to initialize model.\n",
      " |      _kwargs (Dict[str,Any]): Keyword arguments used to initialize model.\n",
      " |      _dispatched (bool): If the _model has been loaded yet with real parameters yet.\n",
      " |      _custom_model (bool): If the value passed to repoid_path_model was a custom model.\n",
      " |      _model (torch.nn.Module): Underlying torch module.\n",
      " |      _envoy (Envoy): Envoy for underlying model.\n",
      " |      _session (Session): Session object if in a Session.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getattr__(self, key: 'Any') -> 'Union[Envoy, InterventionProxy, Any]'\n",
      " |      Wrapper of ._envoy's attributes to access module's inputs and outputs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Any: Attribute.\n",
      " |  \n",
      " |  __init__(self, model_key: 'Union[str, torch.nn.Module]', *args, dispatch: 'bool' = False, meta_buffers: 'bool' = True, **kwargs) -> 'None'\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Wrapper of ._model's representation as the NNsight model's representation.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: Representation.\n",
      " |  \n",
      " |  __setattr__(self, key: 'Any', value: 'Any') -> 'None'\n",
      " |      Overload setattr to create and set an Envoy when trying to set a torch Module.\n",
      " |  \n",
      " |  clear_edits(self) -> 'None'\n",
      " |      Resets the default graph of this model.\n",
      " |  \n",
      " |  dispatch_model(self, *args, **kwargs) -> 'None'\n",
      " |      Dispatch ._model to have real parameters  using ._load(...).\n",
      " |  \n",
      " |  edit(self, *inputs: 'Any', inplace: 'bool' = False, return_context: 'bool' = False, **kwargs: 'Dict[str, Any]') -> 'Union[Tracer, Any]'\n",
      " |      Create a trace context with an edit backend and apply a list of edits.\n",
      " |      \n",
      " |      The edit backend sets a default graph on an NNsight model copy which is\n",
      " |      run on future trace calls.\n",
      " |      \n",
      " |      This operation is not inplace!\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs (tuple[Any])\n",
      " |          inplace (bool): If True, makes edits in-place.\n",
      " |          return_context (bool): If True, returns the editor Tracer context.\n",
      " |          kwargs (Dict[str, Any]): Keyword arguments passed to Tracer initialization, and then downstream to the model's ._execute(...) method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Union[Tracer, Any]: Either the Tracer used for tracing, or the raw output if trace is False.\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |          from nnsight import LanguageModel\n",
      " |      \n",
      " |          gpt2 = LanguageModel(\"openai-community/gpt2)\n",
      " |      \n",
      " |          class ComplexModule(torch.nn.Module):\n",
      " |              def __init__(self):\n",
      " |                  super().__init__()\n",
      " |                  self.one = WrapperModule()\n",
      " |      \n",
      " |              def forward(self, x):\n",
      " |                  return self.one(x)\n",
      " |      \n",
      " |          l0 = gpt2.transformer.h[0]\n",
      " |          l0.attachment = ComplexModule()\n",
      " |      \n",
      " |          with gpt2.edit(\"test\") as gpt2_edited:\n",
      " |              acts = l0.output[0]\n",
      " |              l0.output[0][:] = l0.attachment(acts, hook=True)\n",
      " |      \n",
      " |          with gpt2.trace(MSG_prompt):\n",
      " |              original = l0.output[0].clone().save()\n",
      " |              l0.output[0][:] *= 0.0\n",
      " |              original_output = gpt2.output.logits.save()\n",
      " |      \n",
      " |          with gpt2_edited.trace(MSG_prompt):\n",
      " |              one = l0.attachment.one.output.clone().save()\n",
      " |              l0.attachment.output *= 0.0\n",
      " |              edited_output = gpt2.output.logits.save()\n",
      " |      \n",
      " |          print(original_output)\n",
      " |          print(edited_output)\n",
      " |  \n",
      " |  interleave(self, fn: 'Callable', intervention_graph: 'Graph', *inputs: 'List[List[Any]]', **kwargs) -> 'None'\n",
      " |      Runs some function with some inputs and some graph with the appropriate contexts for this model.\n",
      " |      \n",
      " |      Loads and dispatched ._model if not already done so.\n",
      " |      \n",
      " |      Re-compiles Graph with ._model to prepare for a new execution of graph.\n",
      " |      \n",
      " |      Runs ._prepare_inputs(...) one last time to get total_batch_size.\n",
      " |      \n",
      " |      Handles adding and removing hooks on modules via HookHandler and tracking number of times a module has been called via InterventionHandler.\n",
      " |      \n",
      " |      After execution, garbage collects and clears cuda memory.\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (Callable): Function or method to run.\n",
      " |          intervention_graph (Graph): Intervention graph to interleave with model's computation graph.\n",
      " |          inputs (List[List[Any]]): List of multiple groups of inputs to give to function for each invoker.\n",
      " |  \n",
      " |  scan(self, *inputs, **kwargs) -> 'Tracer'\n",
      " |      Context just to populate fake tenor proxy values using scan and validate.\n",
      " |      Useful when looking for just the shapes of future tensors\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              with model.scan(\" \"):\n",
      " |      \n",
      " |                  dim = model.module.output.shape[-1]\n",
      " |      \n",
      " |              print(dim)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tracer: Tracer context with Noop backend.\n",
      " |  \n",
      " |  session(self, backend: 'Union[Backend, str]' = None, remote: 'bool' = False, blocking: 'bool' = True, **kwargs) -> 'Session'\n",
      " |      Create a session context using a Session.\n",
      " |      \n",
      " |      Args:\n",
      " |          backend (Backend): Backend for this Session object.\n",
      " |          remote (bool): Use RemoteBackend with default url.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Session: Session.\n",
      " |  \n",
      " |  to(self, *args, **kwargs) -> 'Self'\n",
      " |      Override torch.nn.Module.to so this returns the NNSight model, not the underlying module when doing: model = model.to(...)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Envoy: Envoy.\n",
      " |  \n",
      " |  trace(self, *inputs: 'Any', trace: 'bool' = True, invoker_args: 'Dict[str, Any]' = None, backend: 'Union[Backend, str]' = None, remote: 'bool' = False, blocking: 'bool' = True, scan: 'bool' = False, **kwargs: 'Dict[str, Any]') -> 'Union[Tracer, Any]'\n",
      " |      Entrypoint into the tracing and interleaving functionality nnsight provides.\n",
      " |      \n",
      " |      In short, allows access to the future inputs and outputs of modules in order to trace what operations you would like to perform on them.\n",
      " |      This can be as simple as accessing and saving activations for inspection, or as complicated as transforming the activations and gradients in a forward pass over multiple inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs (tuple[Any])\n",
      " |          trace (bool, optional): If to open a tracing context. Otherwise immediately run the model and return the raw output. Defaults to True.\n",
      " |          invoker_args (Dict[str, Any], optional): Keyword arguments to pass to Invoker initialization, and then downstream to the model's .prepare_inputs(...) method. Used when giving input directly to `.trace(...)`. Defaults to None.\n",
      " |          kwargs (Dict[str, Any]): Keyword arguments passed to Tracer initialization, and then downstream to the model's ._execute(...) method.\n",
      " |          backend (Union[Backend, str]): Backend for this Tracer object.\n",
      " |          remote (bool): Use RemoteBackend with default url.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If trace is False and no inputs were provided (nothing to run with)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Union[Tracer, Any]: Either the Tracer used for tracing, or the raw output if trace is False.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |          There are a few ways you can use ``.trace(...)`` depending in your use case.\n",
      " |      \n",
      " |          Lets use this extremely basic model for our examples:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              import torch\n",
      " |              from collections import OrderedDict\n",
      " |      \n",
      " |              input_size = 5\n",
      " |              hidden_dims = 10\n",
      " |              output_size = 2\n",
      " |      \n",
      " |              model = nn.Sequential(OrderedDict([\n",
      " |                  ('layer1', torch.nn.Linear(input_size, hidden_dims)),\n",
      " |                  ('sigma1', torch.nn.Sigmoid()),\n",
      " |                  ('layer2', torch.nn.Linear(hidden_dims, output_size)),\n",
      " |                  ('sigma2', torch.nn.Sigmoid()),\n",
      " |              ]))\n",
      " |      \n",
      " |              example_input = torch.rand((1, input_size))\n",
      " |      \n",
      " |      \n",
      " |          The first example has us running the model with a single example input, and saving the input and output of 'layer2' as well as the final output using the tracing context.\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              from nnsight import NNsight\n",
      " |      \n",
      " |              with NNsight(model).trace(example_input) as model:\n",
      " |      \n",
      " |                  l2_input = model.layer2.input.save()\n",
      " |                  l2_output = model.layer2.output.save()\n",
      " |      \n",
      " |                  output = model.output.save()\n",
      " |      \n",
      " |              print(l2_input)\n",
      " |              print(l2_output)\n",
      " |              print(output)\n",
      " |      \n",
      " |          The second example allows us to divide up multiple inputs into one batch, and scope an inner invoker context to each one.\n",
      " |          We indicate this simply by not passing and positional inputs into `.trace(...)`. The Tracer object then expects you to enter each input via `Tracer.invoke(...)`\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              example_input2 = torch.rand((1, input_size))\n",
      " |      \n",
      " |              with NNsight(model).trace() as model:\n",
      " |      \n",
      " |                  with model.invoke(example_input):\n",
      " |      \n",
      " |                      output1 = model.output.save()\n",
      " |      \n",
      " |                  with model.invoke(example_input2):\n",
      " |      \n",
      " |                      output2 = model.output.save()\n",
      " |      \n",
      " |              print(output1)\n",
      " |              print(output2)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs) -> 'Self | Envoy'\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'proxy_class': 'Type[InterventionProxy]'}\n",
      " |  \n",
      " |  proxy_class = <class 'nnsight.intervention.InterventionProxy'>\n",
      " |      Sub-class for Proxy that adds additional user functionality to proxies.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |          Saving a proxy so it is not deleted at the completion of it's listeners is enabled with ``.save()``:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              with model.trace('The Eiffel Tower is in the city of'):\n",
      " |                  hidden_states = model.lm_head.input.save()\n",
      " |                  logits = model.lm_head.output.save()\n",
      " |      \n",
      " |              print(hidden_states)\n",
      " |              print(logits)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tiny_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with tracing context, customise how nn runs\n",
    "## upon exit, model is ran\n",
    "\n",
    "# random input\n",
    "input = torch.rand((1, input_size))\n",
    "\n",
    "with tiny_model.trace(input) as tracer:\n",
    "    pass\n",
    "\n",
    "## deferred execution\n",
    "## input, output: proxies for eventual input/output of module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
